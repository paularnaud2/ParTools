pytools/conf.py
----------------------------------------------------------------------------------------------------
# This directory contains input, output, log, and temporary files folders.
# If you wish to change it, run import pytools.utils after to initialise the
# new folder.
# Path to confidential data (used by mail package)
# This directory has to contain a conf.txt file and the mail folders corresponding
# to the mail_name passed in the mail function.
# DEBUG = True enables function decorator in utils.deco
# it basically terminates the program if one of the threads
# (or the main thread) throws an exception and prints the exception (full trace)
# in the current log file.
# Warning: DEBUG = True will make pytest fail!
# sql--------------------------------------------------------------------------
# Path to the Oracle instant client
# (the nb of bit has to match your python version)
# yapf: disable
# A conf line should match with one of the two following expected formats:
# 'DB_NAME': CNX_INFO,
# ('DB_NAME', 'ENV_NAME'): CNX_INFO,
# Where CNX_INFO can either be a connection string:
# 'USER/PWD@HOST:PORT/SERVICE_NAME'
#  or a list:
# ['USERNAME', 'PWD', 'TNS_NAME'] or ['USERNAME', 'PWD', 'DSN']
#
# Note that ENV_NAME can be defined to differentiate between two DB of same
# name but of different environment.
# 'XE': ['USERNAME', 'PWD', 'XE_TNS'],
# yapf: enable
----------------------------------------------------------------------------------------------------


pytools/dq/csf.py
----------------------------------------------------------------------------------------------------
# Comparing two lines whose pivot element is equal
----------------------------------------------------------------------------------------------------


pytools/dq/empty_al.py
----------------------------------------------------------------------------------------------------
# cursor variable represents a reading cursor for gl.array_list
# If one of the lists has entirely been read, array of lists
# is generated again without the elements already extracted
# in the output file and while loop is broken (return)
# Determines the smallest element of all non empty list from the current cursor position
# min_col initialised with the first non empty list (cursor != -1)
# min_col and min_elt are searched from init values
----------------------------------------------------------------------------------------------------


pytools/dq/fill_al.py
----------------------------------------------------------------------------------------------------
# Filling buffer array with tmp files
# if current tmp file doesn't exist, we directly jump to the next one
# Reading one tmp file
# Writing part of a tmp file in buffer array so that
# it's length reaches at most c_row_max
# Rewriting tmp file without the lines written in buffer array
# If void, tmp file is deleted
----------------------------------------------------------------------------------------------------


pytools/dq/functions.py
----------------------------------------------------------------------------------------------------
# Pure duplicates are not written in output file
# But key duplicates are (lines differ but key equal)
# Pure duplicates are written in a specific list
# Key duplicates are also written in a specific list
----------------------------------------------------------------------------------------------------


pytools/dq/gl.py
----------------------------------------------------------------------------------------------------
# Mandatory inputs---------------------------------------------------
# Optional inputs----------------------------------------------------
MAX_ROW_LIST = 12 * 10**6  # Max list size. Warning: a too high value may cause a Memory error
MAX_LINE_SPLIT = 900 * 10**3  # If the number of line of the output file exceeds this value, the file is split
MAX_FILE_NB_SPLIT = 10  # Maximum number of split files
SL_STEP = 5 * 10**6  # step_log setting (see README.md)
PIVOT_IDX = 0  # Index of the pivot column (ie. containing keys/IDs used as reference for comparison)
EQUAL_OUT = False  # If True, equal lines are written in the output file
DIFF_OUT = False  # If True, different lines are written in the output file (applies only when EQUAL_OUT = True)
# Default const------------------------------------------------------
----------------------------------------------------------------------------------------------------


pytools/dq/gstf.py
----------------------------------------------------------------------------------------------------
# Generation of sorted temporary files
# Generation of the last temporary file
# Generating output file in the case of only one temporary list
# It is checked whether max number of lines of cur_list is not more than
# fixed limit in module (MAX_ROW_LIST) gl to avoid a memory error
# Generating one temporary file
----------------------------------------------------------------------------------------------------


pytools/dq/sort.py
----------------------------------------------------------------------------------------------------
# nb variable is used to differentiate input file when main run is dq
----------------------------------------------------------------------------------------------------


pytools/mail/gl.py
----------------------------------------------------------------------------------------------------
S_MISSING_CFI = """The email couldn't be sent because the confidential file was not found.
Before running the gmail or no_auth functions, you have to run the init_mail function and set a confidential.txt file.
This file must be saved at the root path using the example provided in the initialised folder."
See quickstart/mail for further guidance."""
----------------------------------------------------------------------------------------------------


pytools/rl/gl.py
----------------------------------------------------------------------------------------------------
# Mandatory inputs---------------------------------------------------
# Either CNX_INFO or DB have to be input. If both are filled, CNX_INFO is taken
CNX_INFO = ''  # Connection string: 'USER/PWD@HOST:PORT/SERVICE_NAME'
DB = ''  # DB name from pytools.conf.CONF_ORACLE
QUERY_IN = ''  # Must be a variabilized query containing '@@IN@@' (see quickstart/rl)
# Optional inputs----------------------------------------------------
ENV = ''  # See comment in conf.CONF_ORACLE for details
# Default const------------------------------------------------------
MAX_DB_CNX = 8  # Maximum number of connections allowed to work in parallel
NB_MAX_ELT_IN_STATEMENT = 1000  # Maximum number of elements in the 'IN' statement per queries
PIVOT_IDX = 0  # Index of the pivot column (column on which the queries and joint are performed)
SKIP_JOIN = False  # If True, no joint is performed and the SQL result is directly output
SKIP_SQL = False  # If True, no SQL query is performed and the joint is directly performed with the available SQL tmp file (only needed for test purpose)
MSG_BOX_END = True  # If True, a message box will pop up at the end of the process, if the processing time is greater than that defined in g.MIN_DUR_MSG_BOX_TRIGGER
# Settable globales
# Process manager
----------------------------------------------------------------------------------------------------


pytools/rl/join.py
----------------------------------------------------------------------------------------------------
# Sorts the input array and deletes its duplicates
# c_e_r cursor saves the right cursor position of the first
# case of key equality. It allows us to come back to the position
# when all equal left keys have been browsed
# Increases the left cursor and checks if the end of the array has been
# reached. In this case, the cursor is set to -1
# Same as incr_c_l but for right cursor
# if s == 'compare_sup':
#     print(key_l)
----------------------------------------------------------------------------------------------------


pytools/rl/main.py
----------------------------------------------------------------------------------------------------
reload(gl)  # reinit globals
----------------------------------------------------------------------------------------------------


pytools/sql/download.py
----------------------------------------------------------------------------------------------------
reload(gl)  # reinit globals
----------------------------------------------------------------------------------------------------


pytools/sql/gl.py
----------------------------------------------------------------------------------------------------
# Mandatory inputs---------------------------------------------------
# Either CNX_INFO or DB have to be input. If both are filled, CNX_INFO is taken
CNX_INFO = ''  # Connection string: 'USER/PWD@HOST:PORT/SERVICE_NAME'
DB = ''  # DB name from pytools.conf.CONF_ORACLE
# QUERY_IN or QUERY_LIST, or both if QUERY_IN is variabilized
# Optional inputs----------------------------------------------------
ENV = ''  # See comment in conf.py for details
OUT_DIR = f"{g.dirs['OUT']}sql_out/"  # Used when MERGE_FILES = False
MAX_DB_CNX = 8  # Maximum number of connections allowed to work in parallel
MERGE_FILES = True  # See quickstart/sql
EXPORT_RANGE = False  # See quickstart/sql
MSG_BOX_END = True  # If True, a message box will pop up at the end of the process, if the processing time is greater than that defined in g.MIN_DUR_MSG_BOX_TRIGGER
# Default const------------------------------------------------------
SL_STEP = 100 * 10**3  # step_log setting (see README.md)
MAX_CHECK_DUP = 1 * 10**6  # If the output number of line exceeds this value, no duplicate check will be performed (avoids potential memory error)
# Strings
# Exceptions
# Data bases in this list will be checked by the is_up_to_date function
# Settable globales
# Process manager
# Execute
# Upload
----------------------------------------------------------------------------------------------------


pytools/sql/gls.py
----------------------------------------------------------------------------------------------------
# Super globals
----------------------------------------------------------------------------------------------------


pytools/sql/groupby.py
----------------------------------------------------------------------------------------------------
# if this is a simple count result without group by statement
# results of different files are directly summed (pandas not needed)
----------------------------------------------------------------------------------------------------


pytools/sql/process.py
----------------------------------------------------------------------------------------------------
# A STOP flag is sent through the manager dict to the main process in order
# to terminate this subprocess and all the threads.
# However a bit of time can pass before all the treads are killed so other thread
# can continue for a few ms while this thread is blocked by the time.sleep
# Output file is initialised with cursor description
# plus range name if EXPORT_RANGE parameter is set to True
----------------------------------------------------------------------------------------------------


pytools/sql/recover.py
----------------------------------------------------------------------------------------------------
# Modifies the query list by deleting element already
# in file list. EC files are also deleted.
----------------------------------------------------------------------------------------------------


pytools/sql/upload.py
----------------------------------------------------------------------------------------------------
reload(gl)  # reinit globals
# First line is dismissed (header)
"""Sends The duration of one insert to the main process.

It is not wanted to send the duration of the first insert as it
might be longer than expected due to cache mechanisms. Hence, the
duration of the second insert is sent to the main process
"""
# We only send the duration of the second insert
----------------------------------------------------------------------------------------------------


pytools/test/gl.py
----------------------------------------------------------------------------------------------------
# Main---------------------------------------------------------------
# test_sql-----------------------------------------------------------
# test_rl-------------------------------------------------------
# test_dq------------------------------------------------------------
# test_tools---------------------------------------------------------
# XML
# Split
# Dup
# Filter
# BF
# test_mail----------------------------------------------------------
----------------------------------------------------------------------------------------------------


pytools/test/sql/interrupt.py
----------------------------------------------------------------------------------------------------
"""This function is used to simulate an unexpected interruption of the
sql.upload function.

md['T'] is the duration of one insert in ms. As the aim is to
simulate an unexpected stop, once this duration is received from the
subprocess, the main process sleeps for this duration before killing
the subprocess. This is believed to introduce some kind of
randomness to the moment where the subprocess is killed (we also
want to test interruption while the the file gl.tmp_file_chunk  is
being written)
"""
----------------------------------------------------------------------------------------------------


pytools/test/sql/iutd.py
----------------------------------------------------------------------------------------------------
# Test no iutd file date db ok
# Test iutd file date ok
# Test no iutd file date db ko
# Test iutd file date ko
----------------------------------------------------------------------------------------------------


pytools/test/tools/__init__.py
----------------------------------------------------------------------------------------------------
# Lines for which this function returns True will be written in the output file
# If not filter function is given in input (ie. gl.FF is not defined),
# no filter will be applied.
----------------------------------------------------------------------------------------------------


pytools/tools/bf.py
----------------------------------------------------------------------------------------------------
reload(dq.gl)  # To reinitialise MAX_ROW_LIST value when pytest is run
----------------------------------------------------------------------------------------------------


pytools/tools/bf_functions.py
----------------------------------------------------------------------------------------------------
# For the buffer, end of previous line is taken to
# guarantee the integrity of searched string
----------------------------------------------------------------------------------------------------


pytools/tools/dup.py
----------------------------------------------------------------------------------------------------
# If in_list elements are hashable
# If not
----------------------------------------------------------------------------------------------------


pytools/tools/filter.py
----------------------------------------------------------------------------------------------------
# Lines for which cond = True are written in the output file
----------------------------------------------------------------------------------------------------


pytools/tools/gl.py
----------------------------------------------------------------------------------------------------
# Dup----------------------------------------------------------------
# XML----------------------------------------------------------------
# Const
# Optional input defaults
SL_STEP_READ = 1000 * 10**3  # step_log setting (see README.md)
SL_STEP_WRITE = 100 * 10**3  # step_log setting (see README.md)
# BF-----------------------------------------------------------------
# Optional input defaults
MAX_LIST_SIZE = 5 * 10**6  # Warning: a too high value may cause a Memory error
BUFFER_SIZE = 100 * 10**3  # Warning: a too high value may cause a Memory error
# Filter-------------------------------------------------------------
# Const
# Optional input defaults
SL_STEP = 500 * 10**3  # step_log setting (see README.md)
# Globals
# Split--------------------------------------------------------------
MAX_LINE = 10**6  # Maximum number of lines for a split file
MAX_FILE_NB = 10  # Maximum number of split files
ADD_HEADER = True  # Adds the header of the input file to each split file
----------------------------------------------------------------------------------------------------


pytools/tools/xml.py
----------------------------------------------------------------------------------------------------
# A new element (not in the first loop) is found
----------------------------------------------------------------------------------------------------


pytools/utils/__init__.py
----------------------------------------------------------------------------------------------------
# Check install and init PT folder
# Imports for package utils
----------------------------------------------------------------------------------------------------


pytools/utils/deco.py
----------------------------------------------------------------------------------------------------
"""When cfg.DEBUG = True, this decorator writes potential exception in
current log file and kills all the running threads (os._exit(1))"""
----------------------------------------------------------------------------------------------------


pytools/utils/file.py
----------------------------------------------------------------------------------------------------
"""Same as os.startfile but with absolute path (more robust)"""
"""Same as os.makedirs but with a delete option which (if True) deletes the
folder if it already exists."""
"""Same as os.path.abspath but with '/' instead of '\'"""
----------------------------------------------------------------------------------------------------


pytools/utils/g.py
----------------------------------------------------------------------------------------------------
# Misc
# Exceptions
# Log
# Path
----------------------------------------------------------------------------------------------------


pytools/utils/log.py
----------------------------------------------------------------------------------------------------
"""For simple use, initialise with init_sl_time()
For multithreaded use, initialise with gen_sl_detail(q_name)"""
----------------------------------------------------------------------------------------------------


pytools/utils/sTools.py
----------------------------------------------------------------------------------------------------
# input variable is used in the case the command expects the user
# to input something (e.g. Y or N). In this case, a binary
# string should be used (e.g. b'Y')
# out = stdout.decode('cp850', errors="ignore")
----------------------------------------------------------------------------------------------------


pytools/utils/string.py
----------------------------------------------------------------------------------------------------
# Oracle equivalent of LIKE operator but with '*' instead of '%'
# Outputs boolean str LIKE like_string
# Example: like('Hello World', 'He*o w*d') => True
----------------------------------------------------------------------------------------------------


quickstart/dq.py
----------------------------------------------------------------------------------------------------
"""
dq (data quality) allows you to compare two big csv files (> 100 Mo).
A detailed result of the comparison is output.

In order for the run_dq function to work correctly, the input files must both
have a pivot column (ie. containing keys/IDs) and be free of 'key duplicates'
meaning having different lines with the same ID. The index of the pivot column
is an input parameter (gl.PIVOT_IDX = 0)

In this script, two files used for testing purposes are compared.
Result interpretation:
COMPARE_RES = in_11: the key is present in the file in_11 and not in the file in_12
COMPARE_RES = in_12: the key is present in the file in_12 and not in the file in_11
COMPARE_RES = in_11|in_12: the key is present in both files but lines differ.

In the last case, the differences are outlined by writing the first and second
files' values separated by '|' for each field that differs. For example 'O|N' in
the field 'ETAT' means that the first file (in_11) has a 'O' and the second file
(in_12) has a 'N'.

For more information, see the README.md file.
"""
----------------------------------------------------------------------------------------------------


quickstart/fix_tnslsnr.py
----------------------------------------------------------------------------------------------------
# This script aims to fix ORA-12514 (problem with local TNS listener)
script = """
alter SYSTEM set LOCAL_LISTENER='(ADDRESS=(PROTOCOL=TCP)(HOST=localhost)(PORT=1521))' scope=both;
alter SYSTEM register;
exit;
"""
----------------------------------------------------------------------------------------------------


quickstart/mail.py
----------------------------------------------------------------------------------------------------
"""
In order for the mail function to be working, you have to initialise a mail
folder by running the 'init_mail' function. This will create a folder in the
MAIL_DIR defined in 'conf.py' ('mails/' by default).

If you want to use the gmail or no_auth functions, you have to set a
confidential.txt file. This file must be saved at the CFI_PATH defined in the
pytools/conf.py file (root by default) using the example provided in the
initialised folder.

The initialised folder contains the mail folders corresponding to the mail_name
passed in the mail function. As you'll notice, it initially contains a 'test'
folder, allowing you to quickly test the function and to provide you with an
example of what a 'mail_name' folder is expected to contain.

So you'll see two files in the mails/test folder:
- template.html: the html template for the body of the mail. It can contain
variables delimited by @@ (in the example @@NAME@@ and @@DATE@@) which are
replaced using the var_dict passed in input.
- recipients.txt: the list of recipients here containing three fictive
recipients. For your test, it is advised to just let one line with your infos.
"""
"""
First run init_mail() and (except if you only want to use mail.outlook) set a
confidential.txt file at the root from the example in 'mails/'."""
"""
Then run one of the following functions (on a personal computer/network try
gmail, on a business computer/network try either no_auth or outlook) to send
a test mail (pointing to mails/test/)."""
# mail.gmail('test', '[Test] Python mail', var_dict=var_dict)
# mail.no_auth('test', '[Test] Python mail', var_dict=var_dict)
# mail.outlook('test', '[Test] Python mail', var_dict=var_dict)
----------------------------------------------------------------------------------------------------


quickstart/reqlist.py
----------------------------------------------------------------------------------------------------
"""
reqlist allows you to quickly retrieve data from an Oracle DB given an input
perimeter. The SQL output can be joint to the input csv file (which can
contain more than one columns). The database is queried in parallel by multiple
threads.

In this example of use, the input file is first created from the 'in.csv' file
(used to populate the TEST table) and contains two columns.
The output contains 3 columns:
2 from the input file and the third (PRM) from the SQL output.

Notes:
- If SKIP_JOIN is False, the SQL output must contain the pivot column (column
used for the queries and for the joint) so that the script can operate the joint.
- The index of the pivot column is an input parameter (gl.PIVOT_IDX = 0)
- In other words, with the default value (PIVOT_IDX), the first field of both
input and SQL output have to contain IDs/keys (as in the example below).
- QUERY_IN accepts either a string or a file path.
- QUERY_IN must be (or point to) a variabilized query, ie. containing '@@IN@@'
after a IN statement, which will be replaced by the elements of the pivot column
while building the final queries being run in parallel.
- Before running this example, you run quickstart/sql_upload.py to create and
populate the TEST table.
- CNX_INFO and DB inputs follow the same rules as for sql.download

For more details, see the README.md file.
"""
# Creates input file from test file
# The input query has to be variabilized ie. contain @@IN@@:
query_in = """
SELECT AFFAIRE, PRM
FROM TEST
WHERE 1=1
AND AFFAIRE IN @@IN@@
"""
----------------------------------------------------------------------------------------------------


quickstart/sql_connect.py
----------------------------------------------------------------------------------------------------
"""
Use this script to troubleshoot your connection problems.
Here you can try to connect either by using one of the following:
- Connection string,
- DNS
- TNS_NAME.
"""
dsn = """
(DESCRIPTION =
(ADDRESS_LIST =
(ADDRESS =
(PROTOCOL = TCP)
(HOST = localhost)
(PORT = 1521)
)
)
(CONNECT_DATA =
(SERVICE_NAME = XE)
)
)
"""
# 1) connect via connection string
# cnx = cx.connect(cnx_str)
# 2) connect via DSN
# cnx = cx.connect("USERNAME", "PWD", dsn)
# 3) connection via TNS_NAME
----------------------------------------------------------------------------------------------------


quickstart/sql_download.py
----------------------------------------------------------------------------------------------------
"""
sql.download allows you to simply and quickly retrieve data from an Oracle DB.
In this file, you'll find four examples of use. For cases 2, 3, 4, the database
is queried in parallel by multiple threads.

1) example_simple: a simple SELECT query is processed (no multithread possible
in this case).

2) example_ql_raw: a raw query list is processed. The 3 results are merged
(default behavior, MERGE_FILES=True) and output in a single csv file.

3) example_ql_var: a variabilized query list is processed. The 3 results are
output in 3 different csv files (MERGE_FILES=False).

4) example_rg: a 'range query' is processed. A range query is a variabilized
query which is executed in parallel for each range of ID contained in the file
whose name appears in the variable. Before running this example, run
quickstart/sql_upload.py to create and populate the TEST table.

Notes:
- QUERY_IN accepts either a string or a file path
- You can input either CNX_INFO or DB, as long as the DB you pass in is defined
in the conf file (pytools/conf.py, CONF_ORACLE)
- As you'll see below, CNX_INFO can either be a connection string:
'USER/PWD@HOST:PORT/SERVICE_NAME'
or a list:
['USERNAME', 'PWD', 'TNS_NAME'] or ['USERNAME', 'PWD', 'DSN']

For more details, see the README.md file.
"""
# Here 'XE_TNS' is a TNS_NAME that has to be defined in the tnsnames.ora file.
# You can also directly put a DSN instead.
# CNX_INFO=cnx_tns,
# DB=db,
"""Expected format for the elements of a raw query list :
[query, name of query]
Note that in the case of a raw query list, no QUERY_IN should be input."""
"""Expected format for the elements of a var query list :
[replacing element, name of query]
Note that in the case of a var query list, a QUERY_IN var should be input;
containing a variabilized query used for the replacing elements."""
"""A range query should contain a variable element formatted as follows:
@@RG_<range_file>@@ where the range file is a csv file located in
'pytools/sql/ranges'"""
query_in_rg = """
SELECT * FROM TEST
WHERE 1=1
AND PRM LIKE '@@RG_PRM_2@@%'
"""
# example_ql_raw()
# example_ql_var()
# example_rg()
----------------------------------------------------------------------------------------------------


quickstart/sql_execute.py
----------------------------------------------------------------------------------------------------
"""
sql.execute allows you to simply execute a SQL script or a PL/SQL procedure
on an Oracle DB.

In this example of use, a create table script is first executed followed by
insert commands. If your script contains a single command or is a PL/SQL
procedure (first example), you have to put PROC=True or nothing (default value);
if it contains several commands (second example), you have to set PROC=False.

Notes:
- SCRIPT_IN accepts either a string or a file path
- CNX_INFO and DB inputs follow the same rules as for sql.download

For more details, see the README.md file.
"""
script_in = """
INSERT INTO TEST VALUES (1, 1, 1);
INSERT INTO TEST VALUES (2, 2, 2);
"""
----------------------------------------------------------------------------------------------------


quickstart/sql_upload.py
----------------------------------------------------------------------------------------------------
"""
sql.upload allows you to simply upload data to an Oracle DB.

In this example of use, the file 'in.csv' is uploaded into the 'XE' DB. You can
input kwargs for the execute function to be run before the upload (EXECUTE_KWARGS).
Here, a create table script is passed ensuring that the 'TEST' table exists
before the upload and that the end result remains the same after each execution.

The input 'VAR_DICT' allows you to pass a dictionary containing variable names
and values to be replaced in the input script. Here, '@@TABLE_NAME@@' will be
replaced by 'TEST'.

Notes:
- SCRIPT_IN accepts either a string or a file path
- CNX_INFO and DB inputs follow the same rules as for sql.download

For more details, see the README.md file.
"""
# CNX_INFO=cnx_str,
# CNX_INFO=cnx_tns,
----------------------------------------------------------------------------------------------------


quickstart/tools_bf.py
----------------------------------------------------------------------------------------------------
# This script allows you to read, search or sort a big file (> 100 Mo).
# Input variables
# in_path = g.dirs['IN'] + "in.csv"
# bf.search_big_file(in_path, out_path, look_for)
# bf.sort_big_file(in_path, out_path)
----------------------------------------------------------------------------------------------------


quickstart/tools_dup.py
----------------------------------------------------------------------------------------------------
"""
The dup script allows you to find and/or remove duplicates as well as sort and
shuffle a csv file or a list.
"""
# Working with files-------------------------------------------------
# in_path = g.dirs['IN'] + "in.csv"
# dup.del_dup(in_path, out_path, True)
# dup.shuffle_csv(in_path, out_path, True)
# Working with lists-------------------------------------------------
# print(dup.del_dup_list(in_list))
----------------------------------------------------------------------------------------------------


quickstart/tools_filter.py
----------------------------------------------------------------------------------------------------
# This script allows you to filter and/or extract columns from a csv file.
# Input variables
# in_path = g.dirs['IN'] + "in.csv"
# Lines for which this function returns True will be written in the output
# file. If no filter function is given in input (ie. gl.FF is not defined),
# no filter will be applied.
# This will extract the columns contained in col_list ('PRM' and 'AFFAIRE') and
# keep only the rows starting with '01' (see filter function)
----------------------------------------------------------------------------------------------------


quickstart/tools_split.py
----------------------------------------------------------------------------------------------------
"""
This script allows you to split a file into multiple files (e.g. if it is too
big to be opened with an app such as Excel). see in pytools/tools/gl for other
parameters.
"""
# Input variables default values
# in_path = g.dirs['IN'] + "in.csv"
----------------------------------------------------------------------------------------------------


quickstart/tools_xml.py
----------------------------------------------------------------------------------------------------
# This script allows you to convert a potentially big xml file into csv.
# Input variables
# in_path = g.dirs['IN'] + "in.xml"
----------------------------------------------------------------------------------------------------


